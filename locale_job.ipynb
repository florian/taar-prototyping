{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAAR â€“ Install numbers by locale\n",
    "\n",
    "This notebook mostly contains code from the [generator job](https://github.com/mozilla/python_mozetl/blob/master/mozetl/taar/taar_locale.py) for finding the most installed addons by locale. It is adapted to include the actual install numbers, normalized by each locale. The result is a dictionary where the keys are locales. The values are dictionaries that contain (addon_id, relative_install_number) pairs.\n",
    "\n",
    "Because this generation process takes quite some time, the results are saved to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'top_addons_by_locale.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the whitelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "AMO_DUMP_BUCKET = 'telemetry-parquet'\n",
    "AMO_DUMP_KEY = 'telemetry-ml/addon_recommender/addons_database.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_amo_external_whitelist():\n",
    "    \"\"\" Download and parse the AMO add-on whitelist.\n",
    "    :raises RuntimeError: the AMO whitelist file cannot be downloaded or contains\n",
    "                          no valid add-ons.\n",
    "    \"\"\"\n",
    "    final_whitelist = []\n",
    "    amo_dump = {}\n",
    "    try:\n",
    "        # Load the most current AMO dump JSON resource.\n",
    "        s3 = boto3.client('s3')\n",
    "        s3_contents = s3.get_object(Bucket=AMO_DUMP_BUCKET, Key=AMO_DUMP_KEY)\n",
    "        amo_dump = json.loads(s3_contents['Body'].read())\n",
    "    except ClientError:\n",
    "        logger.exception(\"Failed to download from S3\", extra={\n",
    "            \"bucket\": AMO_DUMP_BUCKET,\n",
    "            \"key\": AMO_DUMP_KEY})\n",
    "\n",
    "    # If the load fails, we will have an empty whitelist, this may be problematic.\n",
    "    for key, value in amo_dump.items():\n",
    "        addon_files = value.get('current_version', {}).get('files', {})\n",
    "        # If any of the addon files are web_extensions compatible, it can be recommended.\n",
    "        if any([f.get(\"is_webextension\", False) for f in addon_files]):\n",
    "            final_whitelist.append(value['guid'])\n",
    "\n",
    "    if len(final_whitelist) == 0:\n",
    "        raise RuntimeError(\"Empty AMO whitelist detected\")\n",
    "\n",
    "    return final_whitelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the addon data (locale generator job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import click\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "LOCALE_FILE_NAME = 'top10_dict'\n",
    "\n",
    "\n",
    "def get_addons(spark):\n",
    "    \"\"\" Longitudinal sample is selected and freshest ping chosen per client.\n",
    "    Only Firefox release clients are considered.\n",
    "    Columns are exploded (over addon keys)  to include locale of each addon\n",
    "    installation instance system addons, disabled addons, unsigned addons\n",
    "    are filtered out.\n",
    "    Sorting by addon-installations and grouped by locale.\n",
    "    \"\"\"\n",
    "    return spark.sql(\"\"\"\n",
    "        WITH sample AS (\n",
    "        SELECT client_id,\n",
    "        settings[0].locale AS locality,\n",
    "        EXPLODE(active_addons[0])\n",
    "        FROM longitudinal\n",
    "        WHERE normalized_channel='release'\n",
    "          AND build IS NOT NULL\n",
    "          AND build[0].application_name='Firefox'\n",
    "        ),\n",
    "        filtered_sample AS (\n",
    "        SELECT locality, key AS addon_key FROM sample\n",
    "        WHERE value['blocklisted'] = FALSE -- not blocklisted\n",
    "          AND value['type'] = 'extension' -- nice webextensions only\n",
    "          AND value['signed_state'] = 2 -- fully reviewed addons only\n",
    "          AND value['user_disabled'] = FALSE -- active addons only get counted\n",
    "          AND value['app_disabled'] = FALSE -- exclude compatibility disabled addons\n",
    "          AND value['is_system'] = FALSE -- exclude system addons\n",
    "          AND locality <> 'null'\n",
    "          AND key is not null\n",
    "        ),\n",
    "        country_addon_pairs AS (\n",
    "        SELECT\n",
    "        COUNT(*) AS pair_cnts, addon_key, locality\n",
    "        from filtered_sample\n",
    "        GROUP BY locality, addon_key\n",
    "        )\n",
    "        SELECT * FROM country_addon_pairs\n",
    "        ORDER BY locality, pair_cnts DESC\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "def compute_threshold(addon_df):\n",
    "    \"\"\" Get a threshold to remove locales with a small\n",
    "    number of addons installations.\n",
    "    \"\"\"\n",
    "    addon_install_counts = (\n",
    "        addon_df\n",
    "        .groupBy('locality')\n",
    "        .agg({'pair_cnts': 'sum'})\n",
    "    )\n",
    "\n",
    "    # Compute a threshold at the 25th percentile to remove locales with a\n",
    "    # small number of addons installations.\n",
    "    locale_pop_threshold =\\\n",
    "        addon_install_counts.approxQuantile('sum(pair_cnts)', [0.25], 0.2)[0]\n",
    "\n",
    "    # Safety net in case the distribution gets really skewed, we should\n",
    "    # require 2000 addon installation instances to make recommendations.\n",
    "    return 2000 if locale_pop_threshold < 2000 else locale_pop_threshold\n",
    "\n",
    "\n",
    "def transform(addon_df, threshold):\n",
    "    \"\"\" Converts the locale-specific addon data in to a dictionary.\n",
    "    :param addon_df: the locale-specific addon dataframe;\n",
    "    :param threshold: the minimum number of addon-installs per locale;\n",
    "    :param num_addons: requested number of recommendations.\n",
    "    :return: a dictionary {<locale>: ['GUID1', 'GUID2', ...]}\n",
    "    \"\"\"\n",
    "    top10_per = {}\n",
    "\n",
    "    # Decide that we can not make reasonable recommendations without\n",
    "    # a minimum number of addon installations.\n",
    "    grouped_addons = (\n",
    "        addon_df\n",
    "        .groupBy('locality')\n",
    "        .agg({'pair_cnts': 'sum'})\n",
    "        .collect()\n",
    "    )\n",
    "    list_of_locales =\\\n",
    "        [i['locality'] for i in grouped_addons if i['sum(pair_cnts)'] > threshold]\n",
    "\n",
    "    for specific_locale in list_of_locales:\n",
    "        # Most popular addons per locale sorted by number of installs\n",
    "        # are added to the list.\n",
    "        sorted_addon_guids = (\n",
    "            addon_df\n",
    "            .filter(addon_df.locality == specific_locale)\n",
    "            .sort(addon_df.pair_cnts.desc())\n",
    "            .collect()\n",
    "        )FI\n",
    "\n",
    "        # Creates a dictionary of locales (keys) and list of\n",
    "        # recommendation GUIDS (values).\n",
    "        top10_per[specific_locale] = sorted_addon_guids\n",
    "\n",
    "    return top10_per\n",
    "\n",
    "\n",
    "def generate_dictionary(spark):\n",
    "    \"\"\" Wrap the dictionary generation functions in an\n",
    "    easily testable way.\n",
    "    \"\"\"\n",
    "    # Execute spark.SQL query to get fresh addons from longitudinal telemetry data.\n",
    "    addon_df = get_addons(spark)\n",
    "\n",
    "    # Load external whitelist based on AMO data.\n",
    "    amo_whitelist = load_amo_external_whitelist()\n",
    "\n",
    "    # Filter to include only addons present in AMO whitelist.\n",
    "    addon_df_filtered = addon_df.where(col(\"addon_key\").isin(amo_whitelist))\n",
    "\n",
    "    # Make sure not to include addons from very small locales.\n",
    "    locale_pop_threshold = compute_threshold(addon_df_filtered)\n",
    "    return transform(addon_df_filtered, locale_pop_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): 169.254.169.254\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): 169.254.169.254\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "locale_dict = generate_dictionary(sqlContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing relative install numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for locale, addons in locale_dict.items():\n",
    "    max_count = float(max([addon['pair_cnts'] for addon in addons]))\n",
    "    result[locale] = { addon['addon_key']: addon['pair_cnts'] / max_count for addon in addons }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the result in JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH, 'w') as outfile:\n",
    "    json.dump(result, outfile)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "notify_time": "10",
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1249px",
    "left": "0px",
    "right": "2277px",
    "top": "107px",
    "width": "282px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
