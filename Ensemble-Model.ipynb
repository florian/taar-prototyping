{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "111865a2-3f3f-4fe5-92c6-c9c6df18196d"
    }
   },
   "source": [
    "# TAAR â€“ Ensemble Learning\n",
    "\n",
    "Currently we have four different addon recommenders in TAAR. The goal of this project is to combine them into one model. In Machine Learning, this is known as an ensemble model. Generally, ensembles work well if the individual models are quite diverse. There is a good chance that this is the case here as our individual models are all based on different features.\n",
    "\n",
    "The method that we're trying to implement here is known as *linear stacking* or *linear blending*. Our ensemble model uses the output of the previous models as features and learns to weight them, i.e. it learns how useful the individual recommenders are in general. To do this, we have to extend the existing recommenders so that they're able to return weighted recommendations (meaning pairs of recommendations and confidence scores, instead of just an ordered list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.addPyFile(\"./taar/dist/mozilla_taar-0.0.16.dev15+g824aa58.d20171018-py2.7.egg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1b8ecc9d-bae3-4e3e-9319-87cc7c40e6cd"
    }
   },
   "source": [
    "## Collecting and preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "efb2bd5b-f229-472e-b482-d0716db9df39"
    }
   },
   "source": [
    "### Retrieving the relevant variables from the longitudinal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e493852b-cc59-4050-88cd-3dd073cf22ba"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 4 ms, total: 28 ms\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "frame = sqlContext.sql(\"\"\"\n",
    "WITH valid_clients AS (\n",
    "    SELECT *\n",
    "    FROM longitudinal\n",
    "    WHERE normalized_channel='release' AND build IS NOT NULL AND build[0].application_name='Firefox'\n",
    "),\n",
    "\n",
    "addons AS (\n",
    "    SELECT client_id, feature_row.*\n",
    "    FROM valid_clients\n",
    "    LATERAL VIEW explode(active_addons[0]) feature_row\n",
    "),\n",
    "    \n",
    "non_system_addons AS(\n",
    "    SELECT client_id, collect_set(key) AS installed_addons\n",
    "    FROM addons\n",
    "    WHERE NOT value.is_system\n",
    "    GROUP BY client_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    l.client_id,\n",
    "    non_system_addons.installed_addons,\n",
    "    settings[0].locale AS locale,\n",
    "    geo_city[0] AS geo_city,\n",
    "    subsession_length[0] AS subsession_length,\n",
    "    system_os[0].name AS os,\n",
    "    scalar_parent_browser_engagement_total_uri_count[0].value AS total_uri,\n",
    "    scalar_parent_browser_engagement_tab_open_event_count[0].value as tab_open_count,\n",
    "    places_bookmarks_count[0].sum as bookmark_count,\n",
    "    scalar_parent_browser_engagement_unique_domains_count[0].value as unique_tlds,\n",
    "    profile_creation_date[0] as profile_date,\n",
    "    submission_date[0] as submission_date\n",
    "FROM valid_clients l LEFT OUTER JOIN non_system_addons\n",
    "ON l.client_id = non_system_addons.client_id\n",
    "\"\"\")\n",
    "\n",
    "rdd = frame.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = rdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, Spark doesn't correctly adjust the number of partitions in our RDD here. This makes it extremely slow to process the data because we're only using one core instead of `number of cores`  (typically 16 here) times `number of nodes`. Because of this, we manually repartition the RDD here. This will dramatically speed things up when having a cluster with multiple nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2166"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = frame.rdd.repartition(sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ce033f1e-e6a6-4b41-aacf-dfc3cdaf3b47"
    }
   },
   "source": [
    "### Loading addon data (AMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7ee9e42a-8e97-4e88-85d4-990ccedb68b2"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "AMO_DUMP_BUCKET = 'telemetry-parquet'\n",
    "AMO_DUMP_KEY = 'telemetry-ml/addon_recommender/addons_database.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "74908378-57ea-4eeb-8f77-75f7b7324173"
    }
   },
   "outputs": [],
   "source": [
    "def load_amo_external_whitelist():\n",
    "    \"\"\" Download and parse the AMO add-on whitelist.\n",
    "    :raises RuntimeError: the AMO whitelist file cannot be downloaded or contains\n",
    "                          no valid add-ons.\n",
    "    \"\"\"\n",
    "    final_whitelist = []\n",
    "    amo_dump = {}\n",
    "    try:\n",
    "        # Load the most current AMO dump JSON resource.\n",
    "        s3 = boto3.client('s3')\n",
    "        s3_contents = s3.get_object(Bucket=AMO_DUMP_BUCKET, Key=AMO_DUMP_KEY)\n",
    "        amo_dump = json.loads(s3_contents['Body'].read())\n",
    "    except ClientError:\n",
    "        logger.exception(\"Failed to download from S3\", extra={\n",
    "            \"bucket\": AMO_DUMP_BUCKET,\n",
    "            \"key\": AMO_DUMP_KEY})\n",
    "\n",
    "    # If the load fails, we will have an empty whitelist, this may be problematic.\n",
    "    for key, value in amo_dump.items():\n",
    "        addon_files = value.get('current_version', {}).get('files', {})\n",
    "        # If any of the addon files are web_extensions compatible, it can be recommended.\n",
    "        if any([f.get(\"is_webextension\", False) for f in addon_files]):\n",
    "            final_whitelist.append(value['guid'])\n",
    "\n",
    "    if len(final_whitelist) == 0:\n",
    "        raise RuntimeError(\"Empty AMO whitelist detected\")\n",
    "\n",
    "    return final_whitelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "55539eaa-011f-422b-b92a-ec4b1fc9c9ca"
    }
   },
   "source": [
    "### Filtering out legacy addons\n",
    "\n",
    "The collaborative recommender should make recommendations based on WebExtensions. In general, our ensemble should also only recommend WebExtensions. Because of this, we need a way to filter for WebExtensions. We store this collection in two different data structures (list, set) as both will be useful in the remainder of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): 169.254.169.254\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): 169.254.169.254\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "whitelist = load_amo_external_whitelist()\n",
    "whiteset = set(whitelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ed2396bb-3f2e-4fa6-9388-a3d9e34b97fb"
    }
   },
   "outputs": [],
   "source": [
    "def get_whitelisted_addons(installed_addons):\n",
    "    return whiteset.intersection(installed_addons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "003cb37b-c00a-40d3-b512-fbe47aa8e09f"
    }
   },
   "source": [
    "### Completing client data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "f0c13767-4a27-4202-87cb-0babe8b5fbbd"
    }
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse as parse_date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ad65dbfc-2f3c-4b79-a726-68d70339715c"
    }
   },
   "outputs": [],
   "source": [
    "def compute_weeks_ago(formatted_date):\n",
    "    try:\n",
    "        date = parse_date(formatted_date).replace(tzinfo=None)\n",
    "    except ValueError: # raised when the date is in an unknown format\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    days_ago = (datetime.today() - date).days\n",
    "    return days_ago / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "95f8c02e-2d12-4c24-9997-1b17ed78ff2e"
    }
   },
   "outputs": [],
   "source": [
    "def complete_client_data(client_data):\n",
    "    client = client_data.asDict()\n",
    "    \n",
    "    addons = client['installed_addons'] or []\n",
    "    client['installed_addons'] = get_whitelisted_addons(addons)\n",
    "    client['disabled_addons_ids'] = addons\n",
    "    \n",
    "    client['locale'] = str(client['locale'])\n",
    "    client['profile_age_in_weeks'] = compute_weeks_ago(client['profile_date'])\n",
    "    client['submission_age_in_weeks'] = compute_weeks_ago(client['submission_date'])\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "17eece00-9e0c-4231-80d5-a153d589d650"
    }
   },
   "outputs": [],
   "source": [
    "completed_rdd = rdd.map(complete_client_data).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "05cbfe08-2f2d-417b-af43-cb3f406c7aaa"
    }
   },
   "source": [
    "## Computing confidence scores\n",
    "\n",
    "We add a method `get_weighted_recommendations` to each recommender. This method returns a (default) dictionary where the keys are addons and the values indicate how confident the recommender is that the respective addon would be a good recommendation.\n",
    "\n",
    "A default dictionary is used to return `0 ` if a recommender is not in a position to judge how good a potential recommendation would be. The scores returned by this method do not need to be normalized. This is done one step afterwards.\n",
    "\n",
    "**Important note**: The code below is not directly used in the rest of the notebook, it's just here for explanatory and documentation reasons. To use the adapted classes on the worker nodes, they need to be in the TAAR egg, because pickle seems to have problems with subclassing here. Thus, the code below is copied into the TAAR folder from where the TAAR egg is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "67eaa22a-fd0e-4955-a2a6-85dba418bc70"
    }
   },
   "source": [
    "### Collaborative Recommender\n",
    "\n",
    "For the collaborative recommender, we use the confidence scores that were already used internally before. These are based on singular value decomposition: A generator job finds good feature representations for addons and computes the feature values for each addon. By looking at the addons that a user already has installed, we can then find feature values that indicate what kind of addons the user likes. After that, we can compute the confidence scores for addons by calculating the distance between their feature values and the feature values of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from taar.recommenders import CollaborativeRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def java_string_hashcode(s):\n",
    "    h = 0\n",
    "    for c in s:\n",
    "        h = (31 * h + ord(c)) & 0xFFFFFFFF\n",
    "    return ((h + 0x80000000) & 0xFFFFFFFF) - 0x80000000\n",
    "\n",
    "\n",
    "def positive_hash(s):\n",
    "    return java_string_hashcode(s) & 0x7FFFFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NewCollaborativeRecommender(CollaborativeRecommender):\n",
    "    def recommend(self, client_data, limit):\n",
    "        recommendations = self.get_weighted_recommendations(client_data)\n",
    "        \n",
    "        # Sort the suggested addons by their score and return the sorted list of addon\n",
    "        # ids.\n",
    "        sorted_dists = sorted(recommendations.items(), key=op.itemgetter(1), reverse=True)\n",
    "        return [s[0] for s in sorted_dists[:limit]]\n",
    "    \n",
    "    def get_weighted_recommendations(self, client_data):\n",
    "        # Addons identifiers are stored as positive hash values within the model.\n",
    "        installed_addons =\\\n",
    "            [positive_hash(addon_id) for addon_id in client_data.get('installed_addons', [])]\n",
    "\n",
    "        # Build the query vector by setting the position of the queried addons to 1.0\n",
    "        # and the other to 0.0.\n",
    "        query_vector = np.array([1.0 if (entry.get(\"id\") in installed_addons) else 0.0\n",
    "                                 for entry in self.raw_item_matrix])\n",
    "\n",
    "        # Build the user factors matrix.\n",
    "        user_factors = np.matmul(query_vector, self.model)\n",
    "        user_factors_transposed = np.transpose(user_factors)\n",
    "\n",
    "        # Compute the distance between the user and all the addons in the latent\n",
    "        # space.\n",
    "        distances = {}\n",
    "        for addon in self.raw_item_matrix:\n",
    "            # We don't really need to show the items we requested. They will always\n",
    "            # end up with the greatest score. Also filter out legacy addons from the\n",
    "            # suggestions.\n",
    "            hashed_id = str(addon.get(\"id\"))\n",
    "            if (hashed_id in installed_addons or\n",
    "                    hashed_id not in self.addon_mapping or\n",
    "                    self.addon_mapping[hashed_id].get(\"isWebextension\", False) is False):\n",
    "                continue\n",
    "\n",
    "            dist = np.dot(user_factors_transposed, addon.get('features'))\n",
    "            # Read the addon ids from the \"addon_mapping\" looking it\n",
    "            # up by 'id' (which is an hashed value).\n",
    "            addon_id = self.addon_mapping[hashed_id].get(\"id\")\n",
    "            distances[addon_id] = dist\n",
    "\n",
    "        return defaultdict(int, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bbda38c7-42d2-451a-80c2-36786da8ce04"
    }
   },
   "source": [
    "### Similarity Recommender\n",
    "\n",
    "Again, we already have some kind of confidence scores internally that we can reuse for the ensemble. These scores are based on a similarity measure: We find similar users to the current users (e.g. by comparing their locale, OS, number of bookmarks, etc.) and recommend their addons. The confidence score for an addon is then computed by summing up the similarity scores of all users that have the respective addon installed.\n",
    "\n",
    "**TODO**: Compute logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from taar.recommenders.similarity_recommender import SimilarityRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import hamming, canberra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cdist(dist, A, b):\n",
    "    return np.array([dist(a, b) for a in A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\"geo_city\", \"locale\", \"os\"]\n",
    "CONTINUOUS_FEATURES = [\"subsession_length\", \"bookmark_count\", \"tab_open_count\", \"total_uri\", \"unique_tlds\"]\n",
    "\n",
    "class NewSimilarityRecommender(SimilarityRecommender):\n",
    "    def get_similar_donors(self, client_data):\n",
    "        \"\"\"Computes a set of :float: similarity scores between a client and a set of candidate\n",
    "        donors for which comparable variables have been measured.\n",
    "        A custom similarity metric is defined in this function that combines the Hamming distance\n",
    "        for categorical variables with the Canberra distance for continuous variables into a\n",
    "        univariate similarity metric between the client and a set of candidate donors loaded during\n",
    "        init.\n",
    "        :param client_data: a client data payload including a subset fo telemetry fields.\n",
    "        :return: the sorted approximate likelihood ratio (np.array) corresponding to the\n",
    "                 internally computed similarity score and a list of indices that link\n",
    "                 each LR score with the related donor in the |self.donors_pool|.\n",
    "        \"\"\"\n",
    "        client_categorical_feats = [client_data.get(specified_key) for specified_key in CATEGORICAL_FEATURES]\n",
    "        client_continuous_feats = [client_data.get(specified_key) for specified_key in CONTINUOUS_FEATURES]\n",
    "\n",
    "        # Compute the distances between the user and the cached continuous\n",
    "        # and categorical features.\n",
    "        cont_features = cdist(canberra, self.continuous_features, client_continuous_feats)\n",
    "        \n",
    "        # The lambda trick is needed to prevent |cdist| from force-casting the\n",
    "        # string features to double.\n",
    "        cat_features = cdist(hamming, self.categorical_features, client_categorical_feats)\n",
    "\n",
    "        # Take the product of similarities to attain a univariate similarity score.\n",
    "        # Addition of 0.001 to the continuous features avoids a zero value from the\n",
    "        # categorical variables, allowing categorical features precedence.\n",
    "        distances = (cont_features + 0.001) * cat_features\n",
    "\n",
    "        # Compute the LR based on precomputed distributions that relate the score\n",
    "        # to a probability of providing good addon recommendations.\n",
    "        lrs_from_scores =\\\n",
    "            np.array([self.get_lr(distances[i]) for i in range(self.num_donors)])\n",
    "\n",
    "        # Sort the LR values (descending) and return the sorted values together with\n",
    "        # the original indices.\n",
    "        indices = (-lrs_from_scores).argsort()\n",
    "        return lrs_from_scores[indices], indices\n",
    "\n",
    "    def get_weighted_recommendations(self, client_data):\n",
    "        recommendations = defaultdict(int)\n",
    "\n",
    "        for donor_score, donor in zip(*self.get_similar_donors(client_data)):\n",
    "            for addon in self.donors_pool[donor]['active_addons']:\n",
    "                recommendations[addon] += donor_score\n",
    "        \n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ffb63f83-c518-4e50-97cf-28baaf908c5e"
    }
   },
   "source": [
    "### Locale Recommender\n",
    "\n",
    "The confidence scores for the locale recommender are based on the number of addon installations in the respective locale. The more often an addon was installed in the locale, the higher its confidence score. We normalize the results for each locale separately, i.e. the most popular addon in each locale will have a confidence score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from taar.recommenders import LocaleRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOP_ADDONS_BY_LOCALE_FILE_PATH = \"top_addons_by_locale.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NewLocaleRecommender(LocaleRecommender):\n",
    "    def __init__(self, TOP_ADDONS_BY_LOCALE_FILE_PATH):\n",
    "        OriginalLocaleRecommender.__init__(self)\n",
    "        \n",
    "        with open(TOP_ADDONS_BY_LOCALE_FILE_PATH) as data_file:\n",
    "            top_addons_by_locale = json.load(data_file)\n",
    "            \n",
    "        self.top_addons_by_locale = defaultdict(lambda: defaultdict(int), top_addons_by_locale)\n",
    "        \n",
    "    def get_weighted_recommendations(self, client_data):\n",
    "        client_locale = client_data.get('locale', None)\n",
    "        return defaultdict(int, self.top_addons_by_locale[client_locale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "450298ce-5b2e-4519-a342-a469605b08a1"
    }
   },
   "source": [
    "### Legacy Recommender\n",
    "\n",
    "For the legacy recommender, we count how often an addon is listed as a replacement for an installed legacy addon. This count is a natural number that's directly used as the confidence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from taar.recommenders import LegacyRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NewLegacyRecommender(LegacyRecommender):\n",
    "    def get_weighted_recommendations(self, client_data):\n",
    "        recommendations = defaultdict(int)\n",
    "        addons = client_data.get('disabled_addons_ids', [])\n",
    "        \n",
    "        for addon in addons:\n",
    "            for replacement in self.legacy_replacements.get(addon, []):\n",
    "                recommendations[replacement] += 1\n",
    "                \n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing training, validation and test sets\n",
    "\n",
    "For training and validation purposes, only clients that have WebExtension addons installed are useful.\n",
    "\n",
    "The [evaluation notebook](https://github.com/florian/taar-prototyping/blob/master/evaluation.ipynb) lists the portion of clients with a certain number of whitelisted addons. If the cut-off is set to `>= 3` or `>= 4` very few clients are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useful_clients = completed_rdd.filter(lambda client: len(client['installed_addons']) >= 1).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435313"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_clients.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These users are useful for training and evaluating our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, test = useful_clients.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll introduce a small helper function `random_partition`. It takes in an iterable `A` that should be partitioned into to new lists where the first list has a length of `k`. This partitioning is done randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_partition(A, k):\n",
    "    n = len(A)\n",
    "    A = list(A)\n",
    "    indices = set(sample(range(n), k))\n",
    "    \n",
    "    first = []\n",
    "    second = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        element = A[i]\n",
    "        \n",
    "        if i in indices:\n",
    "            first.append(element)\n",
    "        else:\n",
    "            second.append(element)\n",
    "            \n",
    "    return first, second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use this function to randomly decide on a subset of addons that we want to mask for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_masked(addons):\n",
    "    return max(1, len(addons) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_addons(client):\n",
    "    addons = client['installed_addons']\n",
    "    num_mask = get_num_masked(addons)\n",
    "    \n",
    "    masked, unmasked = random_partition(addons, num_mask)\n",
    "    \n",
    "    client['installed_addons'] = unmasked\n",
    "    client['masked_addons'] = masked\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_masked = training.map(mask_addons).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the feature matrices\n",
    "\n",
    "For each user, we want a matrix that contains a row for each whitelisted addon and a column for each recommender. A cell then contains the confidence score that the respective recommender gave for the respective user and addon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n",
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n",
      "INFO:boto3.resources.action:Calling s3:get_object with {u'Bucket': 'telemetry-parquet', u'Key': 'taar/similarity/donors.json'}\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n",
      "INFO:boto3.resources.action:Calling s3:get_object with {u'Bucket': 'telemetry-parquet', u'Key': 'taar/similarity/lr_curves.json'}\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n",
      "INFO:boto3.resources.action:Calling s3:get_object with {u'Bucket': 'telemetry-parquet', u'Key': 'taar/locale/top10_dict.json'}\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n",
      "INFO:boto3.resources.action:Calling s3:get_object with {u'Bucket': 'telemetry-parquet', u'Key': 'taar/legacy/legacy_dict.json'}\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3-us-west-2.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "recommenders = {\n",
    "    \"collaborative\": CollaborativeRecommender(),\n",
    "    \"similarity\": SimilarityRecommender(),\n",
    "    \"locale\": LocaleRecommender(\"./top_addons_by_locale.json\"),\n",
    "    \"legacy\": LegacyRecommender()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_features(client_data):\n",
    "    recommendations = []\n",
    "    matrix = []\n",
    "    \n",
    "    for _, recommender in recommenders.items():\n",
    "        recommendations.append(recommender.get_weighted_recommendations(client_data))\n",
    "\n",
    "    for addon in whitelist:\n",
    "        matrix.append([features[addon] for features in recommendations])\n",
    "\n",
    "    return client_data, np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_unnormalized = training_masked.map(compute_features).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "The optimization algorithms that we use here are much more minimal than what you typically from highly optimized ML libs. Because of this, we need to take special care of properly preprocessing the data.\n",
    "\n",
    "In the following, we perform these operations:\n",
    "- [Min-Max scaling](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "- Changing the locale scores to a double square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_feature_values = X_unnormalized.map(lambda (_, features): np.max(features, axis=0)).reduce(np.maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_locale_scores(scores):\n",
    "    return np.sqrt(np.sqrt(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_features((client, features)):\n",
    "    features = features / max_feature_values\n",
    "    features[:, 0] = preprocess_locale_scores(features[:, 0])\n",
    "    return client, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_unnormalized.map(scale_features).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing recommendations then reduces down to a dot product. These results are then sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weighted_recommendations(client_data, features, weights):\n",
    "    scores = features.dot(weights)\n",
    "    return client_data, np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "83e7764e-9a65-41ce-91fa-21e8358acb20"
    }
   },
   "source": [
    "## Measuring the performance (MAP)\n",
    "\n",
    "We use the [MAP](https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html) measure as an error metric for this optimization problem. The reason for this is mostly that we only have positive data, i.e. we know addons which users like, but we don't really have a lot of data about addons that users hate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def average_precision(client_data, recommendations):\n",
    "    tp = fp = 0.\n",
    "    masked = set(client_data['masked_addons'])\n",
    "    precisions = []\n",
    "    \n",
    "    for recommendation in recommendations:\n",
    "        if whitelist[recommendation] in masked:\n",
    "            tp += 1\n",
    "            precisions.append(tp / (tp + fp))\n",
    "            if tp == len(masked):\n",
    "                break\n",
    "        else:\n",
    "            fp += 1\n",
    "    \n",
    "    if len(precisions) > 0:\n",
    "        return np.mean(precisions)\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0488d2b0-f77e-4b45-8bd7-09cf09dd6680"
    }
   },
   "source": [
    "## Training an ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find recommendations, compute the average precision (AP) and then calculate the mean of that (MAP). This produces a value between 0 and 1. We then subtract this value from 1 because SciPy looks for a function to minimize, not to maximize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cost(weights, X=X):\n",
    "    weighted_recommendations = X.map(lambda (client_data, features):\n",
    "                get_weighted_recommendations(client_data, features, weights)\n",
    "               )\n",
    "    \n",
    "    AP = weighted_recommendations.map(lambda (client_data, recommendations):\n",
    "             average_precision(client_data, recommendations)\n",
    "            )\n",
    "        \n",
    "    MAP = AP.mean()\n",
    "            \n",
    "    return 1 - MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an initial guess\n",
    "\n",
    "There are many ways of choosing initial guesses. A constant vector of 1s seems to be a sensible prior (with properly normalized features it means that all recommenders are equally useful). However, randomly choosing initial values can also be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initial_guess_alternative(n):\n",
    "    return np.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initial_guess(n):\n",
    "    return np.random.random(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging the optimization process\n",
    "\n",
    "SciPy is logging the optimization process to a stdout stream that Jupyter seems to ignore. Because it's extremely useful to see how the optimization process is actually going, we define a helper function that queries `cost` and then also prints the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def verbose_cost(weights):\n",
    "    new_cost = cost(weights)\n",
    "    print \"New guess:\", weights, \"leads to a cost of\", new_cost\n",
    "    return new_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing\n",
    "\n",
    "The 4-element vectors in the following correspond to the recommenders in this order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['locale', 'legacy', 'collaborative', 'similarity']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommenders.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial guess: [ 0.48533936  0.55636737  0.13108097  0.47268632]\n",
      "New guess: [ 0.48533936  0.55636737  0.13108097  0.47268632] leads to a cost of 0.705378749967\n",
      "New guess: [ 1.48533936  0.55636737  0.13108097  0.47268632] leads to a cost of 0.651060536695\n",
      "New guess: [ 1.48533936  1.55636737  0.13108097  0.47268632] leads to a cost of 0.650813378865\n",
      "New guess: [ 1.48533936  1.55636737  1.13108097  0.47268632] leads to a cost of 0.649310991464\n",
      "New guess: [ 1.48533936  1.55636737  1.13108097  1.47268632] leads to a cost of 0.705340053019\n",
      "New guess: [ 2.1812669   1.55953397  1.15032963 -0.24516069] leads to a cost of 0.649269068547\n",
      "New guess: [ 1.82239216  1.56106918  1.15966164 -0.59318293] leads to a cost of 0.68011649334\n",
      "New guess: [ 2.1812669   1.80953154  1.15032963 -0.24405789] leads to a cost of 0.649252783755\n",
      "New guess: [ 2.54022724  1.80852452  1.16249432  0.10379047] leads to a cost of 0.644256645414\n",
      "New guess: [ 2.89564561  1.81024236  1.23708028  0.44746439] leads to a cost of 0.647646561847\n",
      "New guess: [ 2.53251318  1.80852796  1.41237407  0.10301236] leads to a cost of 0.64414121662\n",
      "New guess: [ 2.89159066  1.81025698  1.44762664  0.44915919] leads to a cost of 0.647528399838\n",
      "New guess: [ 2.70572828  1.81110052  1.41716028 -0.07717366] leads to a cost of 0.649620313481\n",
      "New guess: [ 2.28389193  2.22015535  1.41074175  0.2399346 ] leads to a cost of 0.646261875537\n",
      "New guess: [ 2.3711054   1.63964133  1.41141717  0.19202877] leads to a cost of 0.644120853605\n",
      "New guess: [ 2.43505878  1.63485173  1.4144207   0.29928083] leads to a cost of 0.647186124565\n",
      "New guess: [ 2.33574054  1.685659    1.41039694  0.2152001 ] leads to a cost of 0.644750594415\n",
      "New guess: [ 2.33845164  1.60879409  1.41222374  0.07538174] leads to a cost of 0.6440917324\n",
      "New guess: [ 2.33772888  1.60938307  1.47471495  0.07586042] leads to a cost of 0.644009589544\n",
      "New guess: [ 2.42535171  1.52196521  1.49168655  0.07169822] leads to a cost of 0.644082512942\n",
      "New guess: [ 2.29709238  1.56753478  1.47446749  0.0983011 ] leads to a cost of 0.64400555768\n",
      "New guess: [ 2.24370841  1.603316    1.58074647  0.08417185] leads to a cost of 0.643783705506\n",
      "New guess: [ 2.1748745   1.65692838  1.66953226  0.07278378] leads to a cost of 0.643679245126\n",
      "New guess: [ 2.12358501  1.58085683  1.75219668  0.09212549] leads to a cost of 0.643510185439\n",
      "New guess: [ 2.07508988  1.54715919  1.86234429  0.09440456] leads to a cost of 0.643346269316\n",
      "New guess: [ 1.97422953  1.50420451  1.92233998  0.09164693] leads to a cost of 0.643221598451\n",
      "New guess: [ 1.92453869  1.54478908  2.0288606   0.07891627] leads to a cost of 0.643100799414\n",
      "New guess: [  1.91327092e+00   1.49329991e+00   2.11136456e+00   1.19884174e-03] leads to a cost of 0.642887265516\n",
      "New guess: [ 1.89970632  1.44082328  2.19936718 -0.06910581] leads to a cost of 0.648365353754\n",
      "New guess: [ 1.9394283   1.46718024  2.13858713  0.04361035] leads to a cost of 0.642944585739\n",
      "New guess: [ 1.87403908  1.4741998   2.16067306 -0.10505426] leads to a cost of 0.648523392245\n",
      "New guess: [ 1.8630001   1.46215876  2.10191668  0.01908909] leads to a cost of 0.642836652223\n",
      "New guess: [ 1.79043854  1.42201217  2.14060563 -0.0660651 ] leads to a cost of 0.648279810268\n",
      "New guess: [ 1.84250083  1.50948094  2.11467384  0.05201167] leads to a cost of 0.642835425061\n",
      "New guess: [ 1.85109713  1.51133039  2.08771818  0.06515085] leads to a cost of 0.642949187669\n",
      "New guess: [ 1.80931759  1.50574013  2.15730912  0.02081292] leads to a cost of 0.642694870633\n",
      "New guess: [ 1.76667561  1.502212    2.1889827  -0.01193228] leads to a cost of 0.647967626059\n",
      "New guess: [ 1.79880642  1.51868732  2.1374796   0.00334186] leads to a cost of 0.642653097722\n",
      "New guess: [ 1.75406654  1.52468942  2.15130157 -0.0376157 ] leads to a cost of 0.648104492346\n",
      "New guess: [ 1.79964796  1.5344976   2.12561853  0.02753286] leads to a cost of 0.642590926776\n",
      "New guess: [ 1.80705948  1.54562394  2.13258086  0.02341699] leads to a cost of 0.642582412926\n",
      "New guess: [ 1.8324307   1.5378759   2.11636947  0.02025117] leads to a cost of 0.642677453204\n",
      "New guess: [ 1.78610746  1.56740136  2.13436564  0.03117161] leads to a cost of 0.642475887687\n",
      "New guess: [ 1.7683422   1.58515616  2.14444783  0.0467945 ] leads to a cost of 0.642573293813\n",
      "New guess: [ 1.78251233  1.58042962  2.11065488  0.01594986] leads to a cost of 0.642605513884\n",
      "New guess: [ 1.78054623  1.57035675  2.14462481  0.04113296] leads to a cost of 0.642521020339\n",
      "New guess: [ 1.78979051  1.56933176  2.13055628  0.03657832] leads to a cost of 0.64257366894\n",
      "New guess: [ 1.77703572  1.56832422  2.13649636  0.01866351] leads to a cost of 0.642569818419\n",
      "New guess: [ 1.7906249   1.57231243  2.13768078  0.02882232] leads to a cost of 0.642538645867\n",
      "New guess: [ 1.78376045  1.56875883  2.12087857  0.03858027] leads to a cost of 0.642550225269\n",
      "New guess: [ 1.78849908  1.56008802  2.13555681  0.03181311] leads to a cost of 0.642469661922\n",
      "New guess: [ 1.78565927  1.55881203  2.13576351  0.02946291] leads to a cost of 0.64247162563\n",
      "New guess: [ 1.78922731  1.55999212  2.13402434  0.03085045] leads to a cost of 0.642479782485\n",
      "New guess: [ 1.78643644  1.55929605  2.13500109  0.03498616] leads to a cost of 0.642503024201\n",
      "New guess: [ 1.78981947  1.5607      2.1389024   0.03041745] leads to a cost of 0.642470606799\n",
      "New guess: [ 1.78960884  1.5600329   2.13455655  0.0305563 ] leads to a cost of 0.642479242455\n",
      "New guess: [ 1.78884385  1.55924235  2.13589509  0.0318854 ] leads to a cost of 0.6424696855\n",
      "New guess: [ 1.78872172  1.56083818  2.13729181  0.03137475] leads to a cost of 0.642469648976\n",
      "New guess: [ 1.78822472  1.56081853  2.1375662   0.0321691 ] leads to a cost of 0.642469917759\n",
      "New guess: [ 1.78910145  1.56099475  2.13724084  0.03163382] leads to a cost of 0.642470818033\n",
      "New guess: [ 1.78802074  1.56053936  2.13736066  0.0307679 ] leads to a cost of 0.642470238001\n",
      "New guess: [ 1.78855447  1.56126247  2.13712095  0.03133963] leads to a cost of 0.64246964511\n",
      "New guess: [ 1.78944912  1.56156296  2.13692692  0.03149883] leads to a cost of 0.642468703147\n",
      "New guess: [ 1.79031974  1.5618698   2.13675835  0.03176924] leads to a cost of 0.642471907823\n",
      "New guess: [ 1.78939493  1.5613792   2.13649193  0.03161064] leads to a cost of 0.64246956174\n",
      "New guess: [ 1.78888366  1.56227688  2.13682278  0.03116207] leads to a cost of 0.642470407271\n",
      "New guess: [ 1.78949446  1.56130329  2.13703048  0.03110107] leads to a cost of 0.642468636616\n",
      "New guess: [ 1.78930409  1.56119788  2.1371166   0.03117061] leads to a cost of 0.642468161724\n",
      "New guess: [ 1.78930827  1.56101723  2.13752343  0.03137126] leads to a cost of 0.642468951299\n",
      "New guess: [ 1.78892824  1.56143402  2.13716901  0.03097404] leads to a cost of 0.642471136252\n",
      "New guess: [ 1.78930413  1.5610224   2.13696234  0.03124144] leads to a cost of 0.642467927256\n",
      "New guess: [ 1.78931129  1.56096071  2.13698544  0.03113891] leads to a cost of 0.642468350679\n",
      "New guess: [ 1.78913381  1.56110079  2.13685241  0.03135263] leads to a cost of 0.642467895216\n",
      "New guess: [ 1.78908565  1.56104591  2.13693722  0.0314014 ] leads to a cost of 0.642468252896\n",
      "New guess: [ 1.78930455  1.56117993  2.13675174  0.03147118] leads to a cost of 0.642468703147\n",
      "New guess: [ 1.78914061  1.56119741  2.13692572  0.03134059] leads to a cost of 0.64246789135\n",
      "New guess: [ 1.78899322  1.5612648   2.13682717  0.03118688] leads to a cost of 0.642467977338\n",
      "New guess: [ 1.78920341  1.56115866  2.1369562   0.03124825] leads to a cost of 0.642467901602\n",
      "New guess: [ 1.78922145  1.56125043  2.13685221  0.03135291] leads to a cost of 0.642468309046\n",
      "New guess: [ 1.78909777  1.5612084   2.13690914  0.03130194] leads to a cost of 0.64246783806\n",
      "New guess: [ 1.78908268  1.56119342  2.1369308   0.03130511] leads to a cost of 0.642467830073\n",
      "New guess: [ 1.78903065  1.56119853  2.13692727  0.03127382] leads to a cost of 0.642469730839\n",
      "New guess: [ 1.78906923  1.56120367  2.13692489  0.03132982] leads to a cost of 0.642467398037\n",
      "New guess: [ 1.78909932  1.56122045  2.13695178  0.03137242] leads to a cost of 0.642468252798\n",
      "New guess: [ 1.78907354  1.5611577   2.13689284  0.03135361] leads to a cost of 0.642467887229\n",
      "New guess: [ 1.78904312  1.56121681  2.13691663  0.03132686] leads to a cost of 0.642467398037\n",
      "New guess: [ 1.78907067  1.56121267  2.13693081  0.03134053] leads to a cost of 0.642467364919\n",
      "New guess: [ 1.78906693  1.56120876  2.13693613  0.03134138] leads to a cost of 0.642467364919\n",
      "New guess: [ 1.78906875  1.56120668  2.13692319  0.03135216] leads to a cost of 0.642467887229\n",
      "New guess: [ 1.7890772   1.56120938  2.13693288  0.03134127] leads to a cost of 0.642467364919\n",
      "New guess: [ 1.78907283  1.56122012  2.1369394   0.03133059] leads to a cost of 0.642467398037\n",
      "New guess: [ 1.78907033  1.56121341  2.13692953  0.03135041] leads to a cost of 0.642467887229\n"
     ]
    }
   ],
   "source": [
    "num_features = len(recommenders)\n",
    "x0 = get_initial_guess(num_features)\n",
    "print \"Initial guess:\", x0\n",
    "best_weights = minimize(verbose_cost, x0, method=\"COBYLA\", tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64280133639614734"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost([1.278125, 1., 1.8171874999999997, 0.10707070707070707])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental: Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_search(cost, parameter_space):\n",
    "    for parameters in parameter_space:\n",
    "        print parameters, cost(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0) 0.999317795469\n",
      "(0, 0, 0, 1) 0.781044284439\n",
      "(0, 0, 0, 2) 0.781044284439\n",
      "(0, 0, 1, 0) 0.943562693329\n",
      "(0, 0, 1, 1) 0.775298736943\n",
      "(0, 0, 1, 2) 0.777014400398\n",
      "(0, 0, 2, 0) 0.943562693329\n",
      "(0, 0, 2, 1) 0.767080292565\n",
      "(0, 0, 2, 2) 0.775298736943\n",
      "(0, 1, 0, 0) 0.995510515481\n",
      "(0, 1, 0, 1) 0.781035766119\n",
      "(0, 1, 0, 2) 0.780880352461\n",
      "(0, 1, 1, 0) 0.943214127322\n",
      "(0, 1, 1, 1) 0.775202154909\n",
      "(0, 1, 1, 2) 0.776862986849\n",
      "(0, 1, 2, 0) 0.943034455897\n",
      "(0, 1, 2, 1) 0.766951549013\n",
      "(0, 1, 2, 2) 0.775129598268\n",
      "(0, 2, 0, 0) 0.995510515481\n",
      "(0, 2, 0, 1) 0.781786764264\n",
      "(0, 2, 0, 2) 0.781035766119\n",
      "(0, 2, 1, 0) 0.943193566877\n",
      "(0, 2, 1, 1) 0.776209558464\n",
      "(0, 2, 1, 2) 0.776919897482\n",
      "(0, 2, 2, 0) 0.943214127322\n",
      "(0, 2, 2, 1) 0.76798319702\n",
      "(0, 2, 2, 2) 0.775202154909\n",
      "(1, 0, 0, 0) 0.653586710269\n",
      "(1, 0, 0, 1) 0.706249773598\n",
      "(1, 0, 0, 2) 0.713821595475\n",
      "(1, 0, 1, 0) 0.650420413684\n",
      "(1, 0, 1, 1) 0.704830022379\n",
      "(1, 0, 1, 2) 0.713027854432\n",
      "(1, 0, 2, 0) 0.650320396078\n",
      "(1, 0, 2, 1) 0.703943832142\n",
      "(1, 0, 2, 2) 0.712374380858\n",
      "(1, 1, 0, 0) 0.652823591273\n",
      "(1, 1, 0, 1) 0.705832584758\n",
      "(1, 1, 0, 2) 0.713615932023\n",
      "(1, 1, 1, 0) 0.649844424588\n",
      "(1, 1, 1, 1) 0.704397272961\n",
      "(1, 1, 1, 2) 0.712828033415\n",
      "(1, 1, 2, 0) 0.649716652369\n",
      "(1, 1, 2, 1) 0.703557325313\n",
      "(1, 1, 2, 2) 0.712172539026\n",
      "(1, 2, 0, 0) 0.653352678701\n",
      "(1, 2, 0, 1) 0.705896438837\n",
      "(1, 2, 0, 2) 0.713424691705\n",
      "(1, 2, 1, 0) 0.650397013469\n",
      "(1, 2, 1, 1) 0.704522417619\n",
      "(1, 2, 1, 2) 0.712589168725\n",
      "(1, 2, 2, 0) 0.650406273884\n",
      "(1, 2, 2, 1) 0.703674904419\n",
      "(1, 2, 2, 2) 0.711961697999\n",
      "(2, 0, 0, 0) 0.653586710269\n",
      "(2, 0, 0, 1) 0.690287976483\n",
      "(2, 0, 0, 2) 0.706249773598\n",
      "(2, 0, 1, 0) 0.651445337683\n",
      "(2, 0, 1, 1) 0.684947350383\n",
      "(2, 0, 1, 2) 0.705463845082\n",
      "(2, 0, 2, 0) 0.650420413684\n",
      "(2, 0, 2, 1) 0.680590889828\n",
      "(2, 0, 2, 2) 0.704830022379\n",
      "(2, 1, 0, 0) 0.653184699287\n",
      "(2, 1, 0, 1) 0.690123263589\n",
      "(2, 1, 0, 2) 0.706156340238\n",
      "(2, 1, 1, 0) 0.651128308542\n",
      "(2, 1, 1, 1) 0.68474123067\n",
      "(2, 1, 1, 2) 0.705355728315\n",
      "(2, 1, 2, 0) 0.650086878921\n",
      "(2, 1, 2, 1) 0.68035786005\n",
      "(2, 1, 2, 2) 0.704696794839\n",
      "(2, 2, 0, 0) 0.652823591273\n",
      "(2, 2, 0, 1) 0.689644935857\n",
      "(2, 2, 0, 2) 0.705832584758\n",
      "(2, 2, 1, 0) 0.650846311386\n",
      "(2, 2, 1, 1) 0.684340948629\n",
      "(2, 2, 1, 2) 0.705035266025\n",
      "(2, 2, 2, 0) 0.649844424588\n",
      "(2, 2, 2, 1) 0.680023236015\n",
      "(2, 2, 2, 2) 0.704397272961\n"
     ]
    }
   ],
   "source": [
    "space = product(range(3), repeat=4)\n",
    "grid_search(cost, space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to old the method\n",
    "\n",
    "To validate if the MAP numbers that we get are any good, it's useful to compare them to the results of the previous recommendation process. The following is a minimal reimplementation of this `RecommendationManager`. It's used here because we want to use our masked data instead of the data fetched from HBase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecommendationManager:\n",
    "    def __init__(self, recommenders):\n",
    "        self.recommenders = recommenders\n",
    "        \n",
    "    def recommend(self, client_data, limit):\n",
    "        recommendations = []\n",
    "        \n",
    "        for r in self.recommenders:\n",
    "            recommendations += r.recommend(client_data, limit)\n",
    "            \n",
    "            if len(recommendations) >= limit:\n",
    "                break\n",
    "            \n",
    "        return recommendations[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function is similar to `map(superlist.index, sublist`) but ignores elements from the sublist that don't appear in the superlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_elements_to_indices(superlist, sublist):\n",
    "    result = []\n",
    "    \n",
    "    for a in sublist:\n",
    "        for i, b in enumerate(superlist):\n",
    "            if a == b:\n",
    "                result.append(i)\n",
    "                break\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_recommendation_manager(mngr, data=training_masked):\n",
    "    return 1 - data\\\n",
    "        .map(lambda user: (user, mngr.recommend(user, 10)))\\\n",
    "        .map(lambda (user, recommendations): average_precision(user, list_elements_to_indices(whitelist, recommendations)))\\\n",
    "        .mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the previous recommendation manager performs much worse than our new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94540781980452748"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mngr = RecommendationManager([recommenders[\"legacy\"], recommenders[\"collaborative\"], recommenders[\"similarity\"], recommenders[\"locale\"]])\n",
    "evaluate_recommendation_manager(mngr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this comparison is a little bit unfair. The locale recommender is generally extremely useful and can be used as a better baseline. With this ordering (where nearly only the locale recommender is queried), we get a much more comparable result. The results are now in the same ballpark and the ensemble is better by around 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66339567712705083"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mngr = RecommendationManager([recommenders[\"locale\"], recommenders[\"legacy\"], recommenders[\"collaborative\"], recommenders[\"similarity\"]])\n",
    "evaluate_recommendation_manager(mngr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66240704406886164"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mngr = RecommendationManager([recommenders[\"locale\"]])\n",
    "evaluate_recommendation_manager(mngr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set\n",
    "\n",
    "The results using the test set are quite similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_masked = test.map(mask_addons).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_unnormalized = test_masked.map(compute_features).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test_unnormalized.map(scale_features).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66328519154987853"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommendation_manager(mngr, test_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64363248228167091"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(best_weights, X_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "2f1f2259-13cc-419e-9ea1-dbb006a73fd3": {
     "id": "2f1f2259-13cc-419e-9ea1-dbb006a73fd3",
     "layout": "grid",
     "prev": null,
     "regions": {
      "14e63bca-e053-4d62-b454-0ccccfdb2877": {
       "attrs": {
        "height": 0.6666666666666666,
        "pad": 0.01,
        "treemap:weight": 1,
        "width": 0.5,
        "x": 0.5,
        "y": 0
       },
       "id": "14e63bca-e053-4d62-b454-0ccccfdb2877"
      },
      "15eef230-77dc-454f-958b-4a7d29a1b623": {
       "attrs": {
        "height": 0.3333333333333333,
        "pad": 0.01,
        "treemap:weight": 1,
        "width": 1,
        "x": 0,
        "y": 0.6666666666666666
       },
       "id": "15eef230-77dc-454f-958b-4a7d29a1b623"
      },
      "4bb60b22-d190-45a3-91fa-98bb62418f86": {
       "attrs": {
        "height": 0.6666666666666666,
        "pad": 0.01,
        "treemap:weight": 1,
        "width": 0.5,
        "x": 0.25,
        "y": 0
       },
       "id": "4bb60b22-d190-45a3-91fa-98bb62418f86"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1249px",
    "left": "0px",
    "right": "1228.33px",
    "top": "107px",
    "width": "478px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
